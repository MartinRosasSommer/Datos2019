{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.functions import hour, mean\n",
    "import pyspark\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName(\"auctions\").getOrCreate()\n",
    "df_auctions = spark.read.csv('auctions.csv', header=True)\n",
    "rdd_auctions = df_auctions.rdd\n",
    "#AuctionTypeId, country, date, deviceId, platform, refType, sourceId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName(\"events\").getOrCreate()\n",
    "df_events = spark.read.csv('events.csv', header=True)\n",
    "rdd_events = df_events.rdd\n",
    "#date, eventId, refType, refHash, applicationId, attributed, deviceCountryCode, deviceOs, deviceBrand, deviceModel, deviceCity, sessionUserAgent, transId, userAgent, eventUuid, carrier, kind, deviceOs, wifi, connectionType, ipAddress, deviceLanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName(\"installs\").getOrCreate()\n",
    "df_installs = spark.read.csv('installs.csv', header=True)\n",
    "rdd_installs = df_installs.rdd\n",
    "#created, applicationId, refType, refHash, clickHash, attributed, implicit, deviceCountryCode, deviceBrand, deviceModel, sessionUserAgent, userAgent, eventUuid, kind, wifi, transId, ipAddress, deviceLanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_auctions = rdd_auctions.map(lambda x: (x.device_id, datetime.strptime(x.date, \"%Y-%m-%d %H:%M:%S.%f\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ME QUEDO solo con los 3 primeros dias para uqe la distancia maxima sea de 3 dias\n",
    "#arranca el 2019-04-18 00:00:00 asi que el date limite es 2019-04-20 23:59:59\n",
    "limit_date_train = datetime(2019, 4, 20, 23, 59, 59, 999)\n",
    "#uso los siguientes 3 dias para testear\n",
    "limit_date_test_begin = datetime(2019, 4, 21, 0, 0, 0, 0)\n",
    "limit_date_test_end = datetime(2019, 4, 23, 23, 59, 59, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2564673204772915246', datetime.datetime(2019, 4, 23, 18, 58, 0, 842116)),\n",
       " ('4441121667607578179', datetime.datetime(2019, 4, 23, 18, 58, 1, 530771)),\n",
       " ('7721769811471055264', datetime.datetime(2019, 4, 23, 18, 58, 1, 767562)),\n",
       " ('6416039086842158968', datetime.datetime(2019, 4, 23, 18, 58, 2, 363468)),\n",
       " ('1258642015983312729', datetime.datetime(2019, 4, 23, 18, 58, 2, 397559))]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtro por los que son los primeros 3 dias para el train\n",
    "rdd_train = rdd_auctions.filter(lambda x: x[1] < limit_date_train)\n",
    "rdd_test = rdd_auctions.filter(lambda x: x[1] > limit_date_test_begin and x[1] < limit_date_test_end)\n",
    "rdd_test.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora me va a quedar para cada ID la lista de todas las apariciones ordenadas por tiempo\n",
    "rdd_train = rdd_train.groupByKey().mapValues(list).mapValues(sorted)\n",
    "rdd_test = rdd_test.groupByKey().mapValues(list).mapValues(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reappearances(dateList):\n",
    "    \"\"\"\n",
    "    esta funcion recibe una lista de fechas ordenada de las apariciones de un ID\n",
    "    la idea es devolver una lista de tuplas, en la que cada tupla sea asi:\n",
    "    valor 1 = fecha en que aparecio en un auction\n",
    "    valor 2 = cuantas veces apareciÃ³ antes\n",
    "    valor 3 = cuanto tardo en volver a aparecer\n",
    "    \"\"\"\n",
    "    distancias = []\n",
    "    longitud_actual = len(dateList)\n",
    "    if(longitud_actual > 1):\n",
    "        for x in range(longitud_actual):\n",
    "            if(x + 1 < longitud_actual):\n",
    "                distancias.append([dateList[x], x,\n",
    "                                   (dateList[x + 1] - dateList[x]).total_seconds()\n",
    "                                  ])\n",
    "        \n",
    "    return distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora me queda cada registro asi (id, [fecha aparicion, cuantas veces aparecio antes, tiempo que luego tardo en volver a aparecer])\n",
    "rdd_train = rdd_train.flatMapValues(get_all_reappearances)\n",
    "rdd_test = rdd_test.flatMapValues(get_all_reappearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCSVLine(data):\n",
    "  return ','.join(str(d) for d in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_test.take(1)[0][1][0].hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_train = rdd_train.map(lambda x: (x[0], x[1][0].hour > 5, x[1][0].hour > 22, x[1][0].hour > 16,x[1][0].hour, x[1][1], x[1][2])).map(toCSVLine)\n",
    "lines_train.repartition(1).saveAsTextFile('data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_test = rdd_test.map(lambda x: (x[0], x[1][0].hour > 5, x[1][0].hour > 22, x[1][0].hour > 16,x[1][0].hour, x[1][1], x[1][2])).map(toCSVLine)\n",
    "lines_test.repartition(1).saveAsTextFile('data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2932617030932207332',\n",
       "  [datetime.datetime(2019, 4, 21, 20, 52, 34, 600491), 0, 5.683044]),\n",
       " ('2932617030932207332',\n",
       "  [datetime.datetime(2019, 4, 21, 20, 52, 40, 283535), 1, 104871.617357]),\n",
       " ('2932617030932207332',\n",
       "  [datetime.datetime(2019, 4, 23, 2, 0, 31, 900892), 2, 87.786292]),\n",
       " ('2932617030932207332',\n",
       "  [datetime.datetime(2019, 4, 23, 2, 1, 59, 687184), 3, 220.280367]),\n",
       " ('2932617030932207332',\n",
       "  [datetime.datetime(2019, 4, 23, 2, 5, 39, 967551), 4, 130.331401])]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = RandomForestRegressor()\n",
    "#clf.fit(X_train, Y_train)  \n",
    "#y_pred = clf.predict(X_test)\n",
    "rdd_test.take(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
