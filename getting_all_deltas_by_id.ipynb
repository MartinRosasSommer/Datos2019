{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SQLContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "#export PYSPARK_PYTHON=python3.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"auctions\").getOrCreate()\n",
    "df_auctions = spark.read.csv('auctions.csv', header=True)\n",
    "rdd_auctions = df_auctions.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date='2019-04-23 18:58:00.842116', device_id='2564673204772915246', ref_type_id='1', source_id='0'),\n",
       " Row(date='2019-04-23 18:58:01.530771', device_id='4441121667607578179', ref_type_id='7', source_id='0'),\n",
       " Row(date='2019-04-23 18:58:01.767562', device_id='7721769811471055264', ref_type_id='1', source_id='0'),\n",
       " Row(date='2019-04-23 18:58:02.363468', device_id='6416039086842158968', ref_type_id='1', source_id='0'),\n",
       " Row(date='2019-04-23 18:58:02.397559', device_id='1258642015983312729', ref_type_id='1', source_id='0')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_auctions.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora va a ser clave=device_id y valor=date\n",
    "rdd_auctions = rdd_auctions.map(lambda x: (x[1], datetime.strptime(x[0], \"%Y-%m-%d %H:%M:%S.%f\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ME QUEDO solo con los 3 primeros dias para uqe la distancia maxima sea de 3 dias\n",
    "#arranca el 2019-04-18 00:00:00 asi que el date limite es 2019-04-20 23:59:59\n",
    "limit_date_train = datetime(2019, 4, 20, 23, 59, 59, 999)\n",
    "#uso los siguientes 3 dias para testear\n",
    "limit_date_test_begin = datetime(2019, 4, 21, 0, 0, 0, 0)\n",
    "limit_date_test_end = datetime(2019, 4, 23, 23, 59, 59, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro por los que son los primeros 3 dias para el train\n",
    "rdd_train = rdd_auctions.filter(lambda x: x[1] < limit_date_train)\n",
    "rdd_test = rdd_auctions.filter(lambda x: x[1] > limit_date_test_begin and x[1] < limit_date_test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1109595589636746168', datetime.datetime(2019, 4, 20, 23, 57, 27, 912838))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora me va a quedar para cada ID la lista de todas las apariciones ordenadas por tiempo\n",
    "rdd_train = rdd_train.groupByKey().mapValues(list).mapValues(sorted)\n",
    "rdd_test = rdd_test.groupByKey().mapValues(list).mapValues(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reappearances(dateList):\n",
    "    \"\"\"\n",
    "    esta funcion recibe una lista de fechas ordenada de las apariciones de un ID\n",
    "    la idea es devolver una lista de tuplas, en la que cada tupla sea asi:\n",
    "    valor 1 = fecha en que aparecio en un auction\n",
    "    valor 2 = cuanto tardo en volver a aparecer\n",
    "    \"\"\"\n",
    "    distancias = []\n",
    "    longitud_actual = len(dateList)\n",
    "    if(longitud_actual > 1):\n",
    "        for x in range(longitud_actual):\n",
    "            if(x + 1 < longitud_actual):\n",
    "                distancias.append([dateList[x], \n",
    "                                   (pd.to_datetime(dateList[x + 1]) - pd.to_datetime(dateList[x])).total_seconds()\n",
    "                                  ])\n",
    "        \n",
    "    return distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 6, 27, 50, 996158), 848.908411]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 6, 41, 59, 904569), 28513.038578]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 14, 37, 12, 943147), 199.094384]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 14, 40, 32, 37531), 185.775504]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 14, 43, 37, 813035), 255.313251]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 14, 47, 53, 126286), 0.993333]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 14, 47, 54, 119619), 1.044167]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 14, 47, 55, 163786), 15.432364]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 14, 48, 10, 596150), 62.328209]),\n",
       " ('4172466725848941608',\n",
       "  [datetime.datetime(2019, 4, 18, 14, 49, 12, 924359), 67.688715])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ahora me queda cada registro asi (id, [fecha aparicion, tiempo que luego tardo en volver a aparecer])\n",
    "rdd_train = rdd_train.flatMapValues(get_all_reappearances)\n",
    "rdd_test = rdd_test.flatMapValues(get_all_reappearances)\n",
    "rdd_train.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#los mapeo para pasar a csv \n",
    "rdd_train = rdd_train.map(lambda x: (x[0], x[1][0], x[1][1]))\n",
    "rdd_test = rdd_test.map(lambda x: (x[0], x[1][0], x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCSVLine(data):\n",
    "  return ','.join(str(d) for d in data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso a csv. el repartition es para que se cree 1 solo archivo. sino me crea 1 archivo por particion\n",
    "lines_train = rdd_train.map(toCSVLine)\n",
    "lines_train.repartition(1).saveAsTextFile('data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_test = rdd_test.map(toCSVLine)\n",
    "lines_test.repartition(1).saveAsTextFile('data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estas son boludeces para probar los map values con un rdd chiquito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"martin\", datetime(2019, 4, 20, 23, 57, 27, 912838)), (\"martin\",datetime(2019, 4, 24, 23, 57, 27, 912838)),(\"martin\",datetime(2019, 4, 19, 23, 57, 27, 912838)),(\"amrtin\",datetime(2019, 4, 20, 23, 57, 27, 912838)),(\"amrtin\",datetime(2019, 4, 29, 23, 57, 27, 912838))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda x: (x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amrtin', [datetime.datetime(2019, 4, 20, 23, 57, 27, 912838), 777600.0]),\n",
       " ('martin', [datetime.datetime(2019, 4, 19, 23, 57, 27, 912838), 86400.0]),\n",
       " ('martin', [datetime.datetime(2019, 4, 20, 23, 57, 27, 912838), 345600.0])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.groupByKey().mapValues(list).mapValues(sorted).flatMapValues(get_all_reappearances).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
