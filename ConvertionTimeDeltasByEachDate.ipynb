{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.functions import hour, mean\n",
    "import pyspark\n",
    "import random\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName(\"auctions\").getOrCreate()\n",
    "df_auctions = spark.read.csv('auctions.csv', header=True).limit(10000)\n",
    "rdd_auctions = df_auctions.rdd\n",
    "rdd_auctions.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def didConvert():\n",
    "    return bool(random.getrandbits(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_auctions = rdd_auctions.map(lambda x: (x[1], (datetime.strptime(x[0], \"%Y-%m-%d %H:%M:%S.%f\"), didConvert())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_train = rdd_auctions.groupByKey().mapValues(list).mapValues(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_train.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convertion_timeDeltas(dateList):\n",
    "    \"\"\"\n",
    "    esta funcion recibe una lista de fechas ordenada de las apariciones de un ID\n",
    "    la idea es devolver una lista de tuplas, en la que cada tupla sea asi:\n",
    "    valor 1 = fecha en que aparecio en un auction\n",
    "    valor 2 = distancia temporal hasta la siguiente fecha donde convirtió (0: si convirtió en esa fecha,\n",
    "                                                                            3 días: si no convirtió \n",
    "                                                                            en una fecha posterior)\n",
    "    \"\"\"\n",
    "    distancias = []\n",
    "    longitud_actual = len(dateList)\n",
    "    for x in range(longitud_actual):\n",
    "        for y in range(x, longitud_actual):\n",
    "            if(y == longitud_actual - 1 and dateList[y][1] != True):\n",
    "                distancias.append([dateList[x][0], dateList[x][1],\n",
    "                                            timedelta(days=3).total_seconds()\n",
    "                                        ])\n",
    "                break\n",
    "            elif(dateList[y][1] == True):\n",
    "                distancias.append([dateList[x][0], dateList[x][1],\n",
    "                                    (dateList[y][0] - dateList[x][0]).total_seconds()\n",
    "                                    ])\n",
    "                break\n",
    "        \n",
    "    return distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_train_test = rdd_train.flatMapValues(get_convertion_timeDeltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rdd_train_test.take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta(days=3).total_seconds()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
